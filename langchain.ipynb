{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c94386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 21:18:10.346214: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cb73c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 21:18:11.594816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 21:18:11.599047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 21:18:11.599149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3b6b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAI_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv\n\u001b[1;32m      9\u001b[0m _ \u001b[38;5;241m=\u001b[39m load_dotenv(find_dotenv())\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mopen\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OPENAI_API_KEY'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import glob\n",
    "import tiktoken\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "open.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956a8ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1347894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187b9a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The_Effect_of_Student_Teacher_Ratio_on_Truancy.pdf',\n",
       " 'Question_Generation.pdf',\n",
       " 'fec_2016_EDA.v2.pdf',\n",
       " 'w207-music-genre-FINAL-presentation.pdf',\n",
       " 'exploring-ggplot.pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd774b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaders = [PyPDFLoader(pdf) for pdf in glob.glob(\"*.pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b5fee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<langchain.document_loaders.pdf.PyPDFLoader at 0x7f13b7522200>,\n",
       " <langchain.document_loaders.pdf.PyPDFLoader at 0x7f106dd8b1c0>,\n",
       " <langchain.document_loaders.pdf.PyPDFLoader at 0x7f104e28a110>,\n",
       " <langchain.document_loaders.pdf.PyPDFLoader at 0x7f104e28a3e0>,\n",
       " <langchain.document_loaders.pdf.PyPDFLoader at 0x7f104e28a320>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46586778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa51e53a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83f3425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05acd23b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a021e93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ff86c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a56754c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53bb1139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6d7b4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc323065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5730f58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1b29d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"How do lexical metrics compare to semantic metrics for NLP text generation evaluation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb360850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f2dc988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2db8481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be true for our question generation models. That is why\\nwe introduced the blended dataset described in Section\\n3.\\nWe also believed that shuffling the data in the blended\\ndataset would improve model performance by introduc-\\ning more variation into the training process and avoiding\\npotential local minima reflective of consistent patterns\\nfound in the source datasets.\\n4.3 Metrics\\nWe chose evaluation metrics currently popular in evalu-\\nating sequence-to-sequence text generation tasks. These\\nmetrics evaluate the alignment of textual features such\\nas word choice, word order, or semantics between refer-\\nence and candidate sequences. We selected metrics that\\nmeasure similarity in different ways to explore which\\nfeatures contribute most to faithfulness, fluidity, and\\ncoherence.\\nOur metrics fall into two categories: measures of\\nlexical similarity and measures of semantic similarity.\\nWe use BLEU, ROUGE-L, and METEOR to evaluate\\nthe lexical similarity between pairs of generated and\\nreference questions. We use BERTScore and USE to'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d702f53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bded192c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 3, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 13, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 1, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 14, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 3, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 2, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 0, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 0, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 2, 'source': 'Question_Generation.pdf'}\n",
      "{'page': 4, 'source': 'Question_Generation.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6ef76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f7196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
