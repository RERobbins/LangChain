{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b9fd07",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook explores summarization templates and the default prompts supplied by LangChain.\n",
    "\n",
    "It uses the Cohere \"command\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99aa6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "from helpers.utilities import install_if_needed, load_keys, get_env_file_keys\n",
    "from dotenv import find_dotenv, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca51c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_FILE_NAME = '.env_cohere'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda6755d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COHERE_API_KEY']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_env_file_keys(ENV_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9ea121",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_keys(ENV_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf1467d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain is already installed.\n"
     ]
    }
   ],
   "source": [
    "install_if_needed (['langchain'])\n",
    "\n",
    "from langchain.llms import Cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fad6a3",
   "metadata": {},
   "source": [
    "## Load Docs and Instantiate LLM\n",
    "\n",
    "The total number of tokens (prompt and prediction) for that model cannot exceed 4096.  The example we have been using exceeds that limit, so we will avoid examples using stuff chains.  We review this example with stuff chains in our OpenAI and Azure OpenAI notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1666b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "llm = Cohere(model=\"command\", temperature=0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1854f",
   "metadata": {},
   "source": [
    "## Map-Reduce\n",
    "\n",
    "Now we explore the use of map-reduce to address inputs that are too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0823de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import MapReduceDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4522a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54e41d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fd212e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_reduce_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a4dfddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2370 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 s, sys: 52.1 ms, total: 1.63 s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = map_reduce_chain.run(input_documents=chunks, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad41a822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM-powered autonomous agents have the potential to perform complex\n",
      "tasks by decomposing them into smaller, manageable steps. Techniques\n",
      "such as CoT (Chain of Thought) and ToT (Tree of Thoughts) can be used\n",
      "to break down tasks, with or without human input. Self-reflection is\n",
      "important for improving the agent's performance and can be achieved\n",
      "through techniques like ReAct (Reasoning and Acting). LLM+P (LLM plus\n",
      "external classical planner) is another approach that outsources the\n",
      "planning step to an external tool. The paper \"Learning to Learn with\n",
      "Chain of Hindsight and Algorithm Distillation\" proposes two techniques\n",
      "to improve the performance of deep learning models. The Chain of\n",
      "Hindsight (CoH) technique encourages the model to improve its own\n",
      "outputs by presenting it with a sequence of past outputs, each\n",
      "annotated with feedback. The Algorithm Distillation (AD) technique\n",
      "applies the same idea to cross-episode trajectories in reinforcement\n",
      "learning tasks, where an algorithm is encapsulated in a long history-\n",
      "conditioned policy. The paper \"In-Context Reinforcement Learning with\n",
      "Algorithm Distillation\" proposes a new approach to reinforcement\n",
      "learning (RL) that combines the benefits of offline and online RL. The\n",
      "algorithm distills the behavior of a set of source policies, each\n",
      "trained for a specific\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13a18f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'callbacks', 'callback_manager', 'verbose', 'tags', 'metadata', 'input_key', 'output_key', 'llm_chain', 'reduce_documents_chain', 'document_variable_name', 'return_intermediate_steps'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_reduce_chain.__fields__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7561c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a concise summary of the following:\n",
      "\n",
      "\n",
      "\"{text}\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85e7bce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a concise summary of the following:\n",
      "\n",
      "\n",
      "\"{text}\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_chain.reduce_documents_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d6da8",
   "metadata": {},
   "source": [
    "## Map-Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff27c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RefineDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12f473ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_chain = load_summarize_chain(llm, chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bb44e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n",
      "Retrying langchain.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised CohereAPIError: You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 21.7 ms, total: 1.54 s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = refine_chain.run(input_documents=chunks, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cc27771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The original summary is still accurate and does not need to be\n",
      "refined based on the new context. Lil'Log is an LLM-powered autonomous\n",
      "agent system that uses LLM as its core controller. It consists of\n",
      "three key components: planning, memory, and tool use. The agent breaks\n",
      "down large tasks into smaller subgoals, reflects on past actions, and\n",
      "uses memory to retain and recall information. It also learns to call\n",
      "external APIs for extra information. This allows the agent to perform\n",
      "complex tasks efficiently and effectively. The planning component of\n",
      "Lil'Log involves task decomposition, which breaks down large tasks\n",
      "into smaller subgoals. This can be done by LLM with simple prompting,\n",
      "by using task-specific instructions, or with human inputs. Another\n",
      "approach, LLM+P, involves relying on an external classical planner to\n",
      "do long-horizon planning. The memory component of Lil'Log allows the\n",
      "agent to retain and recall information, which is important for self-\n",
      "reflection and improving past action decisions. The tool use component\n",
      "of Lil'Log allows the agent to call external APIs for extra\n",
      "information, which is useful for performing complex tasks. Overall,\n",
      "Lil'Log is a powerful autonomous agent system that combines planning,\n",
      "memory, and tool use to perform complex tasks efficiently and\n",
      "effectively.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "169e8235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'callbacks', 'callback_manager', 'verbose', 'tags', 'metadata', 'input_key', 'output_key', 'initial_llm_chain', 'refine_llm_chain', 'document_variable_name', 'initial_response_name', 'document_prompt', 'return_intermediate_steps'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_chain.__fields__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a0fb8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a concise summary of the following:\n",
      "\n",
      "\n",
      "\"{text}\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "print(refine_chain.initial_llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e0f3d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: {existing_answer}\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "{text}\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\n"
     ]
    }
   ],
   "source": [
    "print(refine_chain.refine_llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e924290f",
   "metadata": {},
   "source": [
    "Regardless of the model, the refine summaries do not seem as good for this example as map reduce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
